\documentclass[final]{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024


% ready for submission
\usepackage{neurips_2024}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables % 42, 57
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors


\title{AlphaGo}
\author{
	Jakkula Adishesh Balaji \\
	AI24BTECH11016 \\ 
	}


\begin{document}
\maketitle

\begin{abstract}
AlphaGo, developed by Google's DeepMind, is a computer program designed to play Go, a complex board game. In 2016, AlphaGo gained international fame by defeating the 9-dan professional Lee Sedol in a five-game match (4-1). This event was a significant milestone for AI and Go, an ancient game where players aim to control the most territory on the board. The victory was particularly surprising nations like Korea where Go is treated as a form of art and Go players are considered noble.
\end{abstract}

\paragraph{}
DeepMind created AlphaGo to investigate how deep learning and neural networks could master Go, a game with an immense number of possible moves and board configurations. Given the game’s complexity, AlphaGo employs a policy network to mimic high-level play, a value network to evaluate board positions, and a tree search to explore future possibilities. In 2015, AlphaGo first gained attention by defeating a 2-dan professional, Fan Hui, 5-0. To test its capabilities, DeepMind challenged Lee Sedol.

\paragraph{}
Throughout the match, AlphaGo's moves were notably and regularly slow, taking 1 to 1.5 minutes per move, unlike human players. In the first game, AlphaGo's deep strategic planning led to Lee Sedol's loss. The second game featured an unexpected move by AlphaGo at move 37, which commentators believed no human would make, resulting in another win for AlphaGo. AlphaGo won the third game, securing the match. This was a blow for human capabilities in the field of Go.

\paragraph{}
The fourth game was pivotal. Lee Sedol made a surprising move at move 78, he created a wedge in the position which initially reduced AlphaGo’s win probability dramatically(14\%). AlphaGo then fell off a cliff and made several errors, leading to Lee Sedol's victory. This move, was calculated to have a probability of just 0.007\% to be played, demonstrated that human creativity could still challenge AI. The final game saw AlphaGo’s effortless win with a 91\% win probability.

\paragraph{}
The introduction of AlphaGo has profoundly impacted Go, revealing that moves previously considered creative by humans are now seen as conventional by machines. This development highlights the potential for AI to enhance human understanding and strategies in complex domains. Lee Sedol’s experience with AlphaGo showed him and the world something new and beautiful about the game. To this day Lee Sedol remains the only player to have defeated AlphaGo.

\section{References}
\url{https://www.youtube.com/watch?v=WXuK6gekU1Y}

\end{document}

